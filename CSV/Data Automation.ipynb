{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6tpdSCVCqJFE"
   },
   "source": [
    "## Importing Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-15T17:57:26.993801Z",
     "start_time": "2025-03-15T17:57:26.734617Z"
    },
    "id": "YfTNLU5Th7Oa"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IohkbEnjqMzk"
   },
   "source": [
    "# !! Important !! Change The Country Name Accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-15T17:57:27.828048Z",
     "start_time": "2025-03-15T17:57:27.825592Z"
    }
   },
   "outputs": [],
   "source": [
    "country = \"USA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-15T17:57:28.345739Z",
     "start_time": "2025-03-15T17:57:28.341009Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 450
    },
    "id": "WFGS10vC-xUk",
    "outputId": "41b4adeb-d0d0-48d8-8ac0-b464944b1248"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'CSV'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m csv_folder \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCSV\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# Define the folder name\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m csv_files \u001b[38;5;241m=\u001b[39m [f \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir(csv_folder) \u001b[38;5;28;01mif\u001b[39;00m f\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)]\n\u001b[1;32m      3\u001b[0m csv_files\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'CSV'"
     ]
    }
   ],
   "source": [
    "csv_folder = \"CSV\"  # Define the folder name\n",
    "csv_files = [f for f in os.listdir(csv_folder) if f.endswith('.csv')]\n",
    "csv_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-15T17:58:15.797811Z",
     "start_time": "2025-03-15T17:58:15.635363Z"
    }
   },
   "outputs": [],
   "source": [
    "for csv in csv_files:\n",
    "    df = pd.read_csv(csv)\n",
    "\n",
    "    # Ensure the 'Date' column is in datetime format\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "    df['Year'] = df['Date'].dt.year\n",
    "    \n",
    "    # Removing , from Prices\n",
    "    try:\n",
    "        df['Price'] = df['Price'].str.replace(',', '', regex=True).astype(float)\n",
    "    except AttributeError:\n",
    "        pass\n",
    "\n",
    "    # Removing % from Change %\n",
    "    try:\n",
    "        df['Change %'] = df['Change %'].str.rstrip('%').astype(float)\n",
    "    except AttributeError:\n",
    "        pass\n",
    "\n",
    "    # Filter for years 2014-2023\n",
    "    df = df[(df['Year'] >= 2014) & (df['Year'] <= 2023)]\n",
    "    df = df[(df['Year'] >= 2014) & (df['Year'] <= 2023)]\n",
    "    df.to_csv(csv, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For Standard Deviation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-15T17:59:17.439886Z",
     "start_time": "2025-03-15T17:59:17.437305Z"
    }
   },
   "outputs": [],
   "source": [
    "def calculate_yearly_std(df):\n",
    "    \"\"\"\n",
    "    Calculates the yearly standard deviation of stock prices and adds a new column.\n",
    "    :param df: DataFrame containing 'Date' and 'Close' price columns.\n",
    "    :return: DataFrame with an additional 'Std Dev of Stock Prices' column.\n",
    "    \"\"\"\n",
    "    # Read the CSV\n",
    "\n",
    "    # Group by year and calculate std dev\n",
    "    df_std = df.groupby(by='Year')['Change %'].std()\n",
    "    df_std = np.array(df_std)\n",
    "    df_std = pd.DataFrame(df_std)\n",
    "    df_std['Year'] = df['Year'].unique()[::-1]\n",
    "    df_std.loc[:,0] = df_std.loc[:,0].round(3)\n",
    "    df_std['Std Dev'] = df_std.iloc[:,0]\n",
    "    df_std.drop(df_std.columns[0], axis=1, inplace=True)\n",
    "    \n",
    "    return df_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For Yearly Covariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-15T17:59:18.173491Z",
     "start_time": "2025-03-15T17:59:18.170845Z"
    }
   },
   "outputs": [],
   "source": [
    "def calculate_yearly_covariance(stock_df, index_df):\n",
    "    \"\"\"\n",
    "    Calculates the yearly covariance between stock prices and index level.\n",
    "    \n",
    "    :param stock_df: DataFrame containing 'Date' and 'Close' price columns for the stock.\n",
    "    :param index_df: DataFrame containing 'Date' and 'Close' price columns for the index.\n",
    "    :return: DataFrame with yearly covariance values.\n",
    "    \"\"\"\n",
    "\n",
    "    # Merge stock and index data on Common 'Date' and 'Year'\n",
    "\n",
    "    merged_df = pd.merge(stock_df, index_df, on=['Date','Year'], how='inner', suffixes=('_Stock', '_Index'))\n",
    "\n",
    "    # Calculate yearly covariance\n",
    "    yearly_cov =  merged_df.groupby('Year')[['Change %_Stock', 'Change %_Index']].apply(lambda x: x.cov().iloc[0, 1])\n",
    "    yearly_cov = np.array(yearly_cov)\n",
    "    yearly_cov = pd.DataFrame(yearly_cov)\n",
    "    yearly_cov['Year'] = stock_df['Year'].unique()[::-1]\n",
    "\n",
    "    if stock_df.equals(index_df):\n",
    "        # Renaming the column to Variance\n",
    "        yearly_cov.rename(columns={yearly_cov.columns[0]: 'Variance'}, inplace=True)\n",
    "\n",
    "        # Reordering the columns\n",
    "        yearly_cov = yearly_cov.loc[:,['Year', 'Variance']]\n",
    "\n",
    "    else: \n",
    "        # Renaming the column to Covariance\n",
    "        yearly_cov.rename(columns={yearly_cov.columns[0]: 'Covariance'}, inplace=True)\n",
    "        \n",
    "        # Reordering the columns\n",
    "        yearly_cov = yearly_cov.loc[:,['Year', 'Covariance']]\n",
    "        \n",
    "    return yearly_cov"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding Beta & Risks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-15T17:59:19.064170Z",
     "start_time": "2025-03-15T17:59:19.061536Z"
    }
   },
   "outputs": [],
   "source": [
    "def calculate_beta_risks(stock, index):\n",
    "    \"\"\"\n",
    "    Calculates the stock market beta from a DataFrame with two columns: \n",
    "    'Stock' and 'Index'. Returns a new DataFrame with an additional column 'Beta'.\n",
    "    \n",
    "    Parameters:\n",
    "        df (pd.DataFrame): A DataFrame with 'Stock' and 'Index' price columns.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: Original DataFrame with an added 'Beta' column.\n",
    "    \"\"\"\n",
    "\n",
    "    yearly_cov = (\n",
    "        calculate_yearly_covariance(stock, index)\n",
    "        .set_index('Year')['Covariance']  # Selecting only 'Covariance'\n",
    "        .div(\n",
    "            calculate_yearly_covariance(index, index)\n",
    "            .set_index('Year')['Variance']  # Selecting only 'Variance'\n",
    "        )\n",
    "    )\n",
    "\n",
    "    yearly_cov = np.array(yearly_cov)\n",
    "    yearly_cov = pd.DataFrame(yearly_cov)\n",
    "    yearly_cov['Year'] = index['Year'].unique()[::-1]\n",
    "    yearly_cov.rename(columns={yearly_cov.columns[0]: 'Beta'}, inplace=True)\n",
    "    yearly_cov = yearly_cov.loc[:,['Year', 'Beta']]\n",
    "    yearly_cov = yearly_cov.dropna(subset=['Beta'])\n",
    "    yearly_cov = pd.merge(yearly_cov, calculate_yearly_covariance(stock, stock), on=['Year'], how='inner')\n",
    "    yearly_cov = yearly_cov.rename(columns={'Variance':'Total Risk'})\n",
    "\n",
    "    # Calculate systematic risk (Beta squared * Index Variance)\n",
    "    yearly_cov['Systematic Risk'] = yearly_cov['Total Risk'] * (yearly_cov['Beta'] ** 2)\n",
    "\n",
    "    # Calculate idiosyncratic risk (Total Risk - Systematic Risk)\n",
    "    yearly_cov['Idiosyncratic Risk'] = yearly_cov.apply(\n",
    "        lambda row: -((abs(row['Total Risk'] - row['Systematic Risk']))**0.5) \n",
    "        if (row['Total Risk'] - row['Systematic Risk']) < 0 \n",
    "        else (abs(row['Total Risk'] - row['Systematic Risk']))**0.5, \n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "\n",
    "    return yearly_cov"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Existing Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensure_minimum_rows(df):\n",
    "    \"\"\"\n",
    "    Ensures that a DataFrame has at least 10 rows. If it has fewer, it adds NaN rows \n",
    "    except for the 'Year' column, which is filled with missing years between 2014 and 2023.\n",
    "    \n",
    "    Parameters:\n",
    "        df (pd.DataFrame): Must contain a 'Year' column.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with at least 10 rows.\n",
    "    \"\"\"\n",
    "    \n",
    "    if 'Year' not in df.columns:\n",
    "        raise ValueError(\"The DataFrame must contain a 'Year' column.\")\n",
    "    \n",
    "    # Get existing years and count current rows\n",
    "    existing_years = set(df['Year'])\n",
    "    num_rows = len(df)\n",
    "    \n",
    "    if num_rows >= 10:\n",
    "        return df  # No need to add rows\n",
    "    \n",
    "    # Find missing years within the range 2014-2023\n",
    "    possible_years = set(range(2014, 2024))  # 2024 is exclusive\n",
    "    missing_years = sorted(possible_years - existing_years)\n",
    "    \n",
    "    # Determine how many extra rows are needed\n",
    "    rows_needed = 10 - num_rows\n",
    "    extra_years = missing_years[:rows_needed]  # Take only required years\n",
    "    \n",
    "    # Create a DataFrame with NaN values in all other columns\n",
    "    nan_rows = pd.DataFrame({col: np.nan for col in df.columns}, index=range(rows_needed))\n",
    "    nan_rows['Year'] = extra_years  # Fill 'Year' column with missing years\n",
    "    \n",
    "    # Concatenate original and new rows\n",
    "    df = pd.concat([df, nan_rows], ignore_index=True)\n",
    "    df = df.sort_values(by='Year', ascending=True)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Index Calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = pd.read_csv('Index.csv')\n",
    "index_price = index.loc[:,['Date', 'Price', 'Change %', 'Year']][::-1]\n",
    "index_std = calculate_yearly_std(index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating The Excel Sheets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excel file 'USA_beta_risks.xlsx' created successfully!\n"
     ]
    }
   ],
   "source": [
    "# Create a new Excel writer object\n",
    "with pd.ExcelWriter(f\"{country}_beta_risks.xlsx\", engine=\"xlsxwriter\") as writer:\n",
    "\n",
    "    for csv_file in csv_files:\n",
    "        if csv_file != 'Index.csv':\n",
    "            # Reading in from CSV File\n",
    "            temp_df = pd.read_csv(csv_file)\n",
    "\n",
    "            # Merging with Index\n",
    "            std_dev_df = pd.merge(calculate_yearly_std(temp_df), index_std, on='Year', how='inner', suffixes=(' of Stock', ' of Index'))\n",
    "\n",
    "            # Calulating Beta & 3 Risks\n",
    "            beta_risks_df = calculate_beta_risks(temp_df, index)\n",
    "\n",
    "            # Merge the Stddev and Beta Dataframes\n",
    "            merged_df = pd.merge(std_dev_df, beta_risks_df, on='Year', how='inner')\n",
    "\n",
    "            # Ensuring 10 rows are there (2014 to 2023)\n",
    "            merged_df = ensure_minimum_rows(merged_df)\n",
    "\n",
    "            # Using first 9 letters to name the Excel Sheet\n",
    "            sheet_name = csv_file[:9] \n",
    "            \n",
    "            # Writing to a separate sheet\n",
    "            merged_df.to_excel(writer, sheet_name=sheet_name, index=False)  \n",
    "\n",
    "print(f\"Excel file '{country}_beta_risks.xlsx' created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excel file 'USA_pct_change.xlsx' created successfully!\n"
     ]
    }
   ],
   "source": [
    "with pd.ExcelWriter(f\"{country}_pct_change.xlsx\", engine=\"xlsxwriter\") as writer:\n",
    "    for csv_file in csv_files:\n",
    "        # Read CSV and process stock data\n",
    "        df = pd.read_csv(csv_file)\n",
    "        \n",
    "        # Convert Date columns to datetime (without converting to strings)\n",
    "        df['Date'] = pd.to_datetime(df['Date'])\n",
    "        index_copy = index.copy()\n",
    "        index_copy['Date'] = pd.to_datetime(index_copy['Date'])\n",
    "\n",
    "        # Select relevant columns\n",
    "        df = df[['Date', 'Price', 'Change %']]\n",
    "        index_copy = index_copy[['Date', 'Price', 'Change %']]\n",
    "        \n",
    "        # Merge using datetime columns\n",
    "        df = pd.merge(df, index_copy, on='Date', suffixes=(' in Stock Price', ' in Index Level'))\n",
    "        \n",
    "        # Rename columns\n",
    "        df = df.rename(columns={'Price in Stock Price': 'Stock Price', 'Price in Index Level': 'Index Level'})\n",
    "\n",
    "        # Write to Excel\n",
    "        sheet_name = csv_file[:9]  # Cleaner sheet name\n",
    "        df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "\n",
    "print(f\"Excel file '{country}_pct_change.xlsx' created successfully!\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

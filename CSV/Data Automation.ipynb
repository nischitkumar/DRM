{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6tpdSCVCqJFE"
   },
   "source": [
    "## Importing Modules"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "YfTNLU5Th7Oa",
    "ExecuteTime": {
     "end_time": "2025-03-08T11:35:01.141446Z",
     "start_time": "2025-03-08T11:35:01.139195Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ],
   "outputs": [],
   "execution_count": 25
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IohkbEnjqMzk"
   },
   "source": [
    "# !! Important !! Change The Country Name Accordingly"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T11:35:01.883930Z",
     "start_time": "2025-03-08T11:35:01.882066Z"
    }
   },
   "source": [
    "country = \"USA\""
   ],
   "outputs": [],
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 450
    },
    "id": "WFGS10vC-xUk",
    "outputId": "41b4adeb-d0d0-48d8-8ac0-b464944b1248",
    "ExecuteTime": {
     "end_time": "2025-03-08T11:35:02.382796Z",
     "start_time": "2025-03-08T11:35:02.379480Z"
    }
   },
   "source": [
    "csv_files = [f for f in os.listdir() if f.endswith('.csv')]\n",
    "csv_files"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Vistra Energy Stock Price History.csv',\n",
       " 'Targa Resources Stock Price History.csv',\n",
       " 'Diamondback Stock Price History.csv',\n",
       " 'Baker Hughes Stock Price History.csv',\n",
       " 'American Electric Power Stock Price History.csv',\n",
       " 'Marathon Petroleum Stock Price History.csv',\n",
       " 'Sempra Energy Stock Price History.csv',\n",
       " 'Hess Stock Price History.csv',\n",
       " 'MPLX LP Stock Price History.csv',\n",
       " 'Valero Energy Stock Price History.csv',\n",
       " 'Phillips 66 Stock Price History.csv',\n",
       " 'Schlumberger Stock Price History.csv',\n",
       " 'Dominion Energy Stock Price History.csv',\n",
       " 'Occidental Stock Price History.csv',\n",
       " 'Cheniere Energy Stock Price History.csv']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T11:35:03.965534Z",
     "start_time": "2025-03-08T11:35:03.840118Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for csv in csv_files:\n",
    "    df = pd.read_csv(csv)\n",
    "\n",
    "    # Ensure the 'Date' column is in datetime format\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "    df['Year'] = df['Date'].dt.year\n",
    "\n",
    "\n",
    "    # Filter for years 2014-2023\n",
    "    df = df[(df['Year'] >= 2014) & (df['Year'] <= 2023)]\n",
    "    df = df[(df['Year'] >= 2014) & (df['Year'] <= 2023)]\n",
    "    df.to_csv(csv, index=False)"
   ],
   "outputs": [],
   "execution_count": 28
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Percent Change"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T11:34:54.917043Z",
     "start_time": "2025-03-08T11:34:54.914479Z"
    }
   },
   "source": [
    "def percentage_change(df, index=False):\n",
    "    df[f'% Change in {'Stock' if index == False else 'Index'} {'Prices' if index == False else 'Level'}'] = df['Price'].pct_change() * 100\n",
    "    return df"
   ],
   "outputs": [],
   "execution_count": 24
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For Standard Deviation Data"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T11:32:13.500428Z",
     "start_time": "2025-03-08T11:32:13.497813Z"
    }
   },
   "source": [
    "def calculate_yearly_std(df, index=False):\n",
    "    \"\"\"\n",
    "    Calculates the yearly standard deviation of stock prices and adds a new column.\n",
    "    :param df: DataFrame containing 'Date' and 'Close' price columns.\n",
    "    :return: DataFrame with an additional 'Std Dev of Stock Prices' column.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    # Calculate yearly standard deviation\n",
    "    std_dev = df.groupby('Year')['Price'].std()\n",
    "        \n",
    "    # Merge with original DataFrame\n",
    "    df = df.merge(std_dev.rename(f'Std Dev of {'Stock' if index == False else 'Index'} {'Prices' if index == False else 'Level'}'), on='Year', how='left')\n",
    "\n",
    "    if index == False:\n",
    "        df = df.drop(['Date', 'Price', 'Vol.', 'Change %', 'Open', 'High', 'Low'], axis='columns').drop_duplicates(f'Std Dev of {'Stock' if index == False else 'Index'} {'Prices' if index == False else 'Level'}')\n",
    "    else:\n",
    "        df = df.drop(['Date', 'Price', '% Change in Index Level'], axis='columns').drop_duplicates(f'Std Dev of {'Stock' if index == False else 'Index'} {'Prices' if index == False else 'Level'}')\n",
    "    \n",
    "    return df.sort_index(ascending=False)"
   ],
   "outputs": [],
   "execution_count": 16
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For Yearly Covariance"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T11:32:14.590806Z",
     "start_time": "2025-03-08T11:32:14.587236Z"
    }
   },
   "source": [
    "def calculate_yearly_covariance(stock_df, index_df):\n",
    "    \"\"\"\n",
    "    Calculates the yearly covariance between stock prices and index level.\n",
    "    \n",
    "    :param stock_df: DataFrame containing 'Date' and 'Close' price columns for the stock.\n",
    "    :param index_df: DataFrame containing 'Date' and 'Close' price columns for the index.\n",
    "    :return: DataFrame with yearly covariance values.\n",
    "    \"\"\"\n",
    "    # Ensure 'Date' column is in datetime format\n",
    "    stock_df['Date'] = pd.to_datetime(stock_df['Date'])\n",
    "    index_df['Date'] = pd.to_datetime(index_df['Date'])\n",
    "    \n",
    "    # Extract year\n",
    "    stock_df['Year'] = stock_df['Date'].dt.year\n",
    "    index_df['Year'] = index_df['Date'].dt.year\n",
    "\n",
    "    # Filter for years 2014-2023\n",
    "    stock_df = stock_df[(stock_df['Year'] >= 2014) & (stock_df['Year'] <= 2023)]\n",
    "    index_df = index_df[(index_df['Year'] >= 2014) & (index_df['Year'] <= 2023)]\n",
    "\n",
    "    # Merge stock and index data on 'Date'\n",
    "    merged_df = stock_df[['Date', 'Year', 'Price']].merge(index_df[['Date', 'Year', 'Price']], on=['Date', 'Year'], suffixes=('_Stock', '_Index'))\n",
    "\n",
    "    # Calculate yearly covariance\n",
    "    yearly_cov =  merged_df.groupby('Year')[['Price_Stock', 'Price_Index']].apply(lambda x: x.cov().iloc[0, 1])\n",
    "\n",
    "    yearly_cov = pd.DataFrame(yearly_cov)\n",
    "\n",
    "    yearly_cov.rename(columns={yearly_cov.columns[0]: 'Covariance'}, inplace=True)\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    cov_df = yearly_cov.reset_index()\n",
    "\n",
    "    return cov_df"
   ],
   "outputs": [],
   "execution_count": 17
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding Beta & Risks"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T11:32:15.538175Z",
     "start_time": "2025-03-08T11:32:15.535555Z"
    }
   },
   "source": [
    "def calculate_beta_risks(df, index, merged_df):\n",
    "    \"\"\"\n",
    "    Calculates the stock market beta from a DataFrame with two columns: \n",
    "    'Stock' and 'Index'. Returns a new DataFrame with an additional column 'Beta'.\n",
    "    \n",
    "    Parameters:\n",
    "        df (pd.DataFrame): A DataFrame with 'Stock' and 'Index' price columns.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: Original DataFrame with an added 'Beta' column.\n",
    "    \"\"\"\n",
    "\n",
    "    yearly_cov = calculate_yearly_covariance(df, index)\n",
    "    yearly_cov = yearly_cov['Covariance']\n",
    "\n",
    "    # Calculating Beta and adding it as a new column (constant for all rows)\n",
    "    merged_df['Beta'] = yearly_cov.div(merged_df['Std Dev of Index Level'] ** 2)\n",
    "\n",
    "    # Calculate total risk (variance of stock returns)\n",
    "    merged_df['Total Risk'] = merged_df['Std Dev of Stock Prices'] ** 2\n",
    "\n",
    "    # Calculate systematic risk (Beta squared * Index Variance)\n",
    "    merged_df['Systematic Risk'] = merged_df['Total Risk'] * (merged_df['Beta'] ** 2)\n",
    "\n",
    "    # Calculate idiosyncratic risk (Total Risk - Systematic Risk)\n",
    "    merged_df['Idiosyncratic Risk'] = merged_df['Total Risk'] - merged_df['Systematic Risk']\n",
    "\n",
    "    return merged_df"
   ],
   "outputs": [],
   "execution_count": 18
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Existing Rows"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T11:32:16.351254Z",
     "start_time": "2025-03-08T11:32:16.348378Z"
    }
   },
   "source": [
    "def ensure_minimum_rows(df):\n",
    "    \"\"\"\n",
    "    Ensures that a DataFrame has at least 10 rows. If it has fewer, it adds NaN rows \n",
    "    except for the 'Year' column, which is filled with missing years between 2014 and 2023.\n",
    "    \n",
    "    Parameters:\n",
    "        df (pd.DataFrame): Must contain a 'Year' column.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with at least 10 rows.\n",
    "    \"\"\"\n",
    "    \n",
    "    if 'Year' not in df.columns:\n",
    "        raise ValueError(\"The DataFrame must contain a 'Year' column.\")\n",
    "    \n",
    "    # Get existing years and count current rows\n",
    "    existing_years = set(df['Year'])\n",
    "    num_rows = len(df)\n",
    "    \n",
    "    if num_rows >= 10:\n",
    "        return df  # No need to add rows\n",
    "    \n",
    "    # Find missing years within the range 2014-2023\n",
    "    possible_years = set(range(2014, 2024))  # 2024 is exclusive\n",
    "    missing_years = sorted(possible_years - existing_years)\n",
    "    \n",
    "    # Determine how many extra rows are needed\n",
    "    rows_needed = 10 - num_rows\n",
    "    extra_years = missing_years[:rows_needed]  # Take only required years\n",
    "    \n",
    "    # Create a DataFrame with NaN values in all other columns\n",
    "    nan_rows = pd.DataFrame({col: np.nan for col in df.columns}, index=range(rows_needed))\n",
    "    nan_rows['Year'] = extra_years  # Fill 'Year' column with missing years\n",
    "    \n",
    "    # Concatenate original and new rows\n",
    "    df = pd.concat([df, nan_rows], ignore_index=True)\n",
    "    df = df.sort_values(by='Year', ascending=True)\n",
    "    return df\n"
   ],
   "outputs": [],
   "execution_count": 19
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Index Calculations"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T11:32:17.400610Z",
     "start_time": "2025-03-08T11:32:17.094330Z"
    }
   },
   "source": [
    "index = pd.read_csv('Index/Index.csv')\n",
    "index = index.iloc[:, :2]\n",
    "index['Price'] = index['Price'].str.replace(',', '', regex=True).astype(float)\n",
    "index = percentage_change(index, index=True)\n",
    "index_std = calculate_yearly_std(index, index=True)"
   ],
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Year'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[20], line 5\u001B[0m\n\u001B[1;32m      3\u001B[0m index[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mPrice\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m index[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mPrice\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mstr\u001B[38;5;241m.\u001B[39mreplace(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m,\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m'\u001B[39m, regex\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\u001B[38;5;241m.\u001B[39mastype(\u001B[38;5;28mfloat\u001B[39m)\n\u001B[1;32m      4\u001B[0m index \u001B[38;5;241m=\u001B[39m percentage_change(index, index\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m----> 5\u001B[0m index_std \u001B[38;5;241m=\u001B[39m \u001B[43mcalculate_yearly_std\u001B[49m\u001B[43m(\u001B[49m\u001B[43mindex\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindex\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[16], line 9\u001B[0m, in \u001B[0;36mcalculate_yearly_std\u001B[0;34m(df, index)\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;124;03mCalculates the yearly standard deviation of stock prices and adds a new column.\u001B[39;00m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;124;03m:param df: DataFrame containing 'Date' and 'Close' price columns.\u001B[39;00m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;124;03m:return: DataFrame with an additional 'Std Dev of Stock Prices' column.\u001B[39;00m\n\u001B[1;32m      6\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m      8\u001B[0m \u001B[38;5;66;03m# Calculate yearly standard deviation\u001B[39;00m\n\u001B[0;32m----> 9\u001B[0m std_dev \u001B[38;5;241m=\u001B[39m \u001B[43mdf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgroupby\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mYear\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mPrice\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mstd()\n\u001B[1;32m     11\u001B[0m \u001B[38;5;66;03m# Merge with original DataFrame\u001B[39;00m\n\u001B[1;32m     12\u001B[0m df \u001B[38;5;241m=\u001B[39m df\u001B[38;5;241m.\u001B[39mmerge(std_dev\u001B[38;5;241m.\u001B[39mrename(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mStd Dev of \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mStock\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mif\u001B[39;00m\u001B[38;5;250m \u001B[39mindex\u001B[38;5;250m \u001B[39m\u001B[38;5;241m==\u001B[39m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01melse\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mIndex\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mPrices\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mif\u001B[39;00m\u001B[38;5;250m \u001B[39mindex\u001B[38;5;250m \u001B[39m\u001B[38;5;241m==\u001B[39m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01melse\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mLevel\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m), on\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mYear\u001B[39m\u001B[38;5;124m'\u001B[39m, how\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mleft\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[0;32m~/Documents/Programming/PyCharm Projects/.venv/lib/python3.12/site-packages/pandas/core/frame.py:9183\u001B[0m, in \u001B[0;36mDataFrame.groupby\u001B[0;34m(self, by, axis, level, as_index, sort, group_keys, observed, dropna)\u001B[0m\n\u001B[1;32m   9180\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m level \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m by \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m   9181\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mYou have to supply one of \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mby\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m and \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlevel\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m-> 9183\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mDataFrameGroupBy\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   9184\u001B[0m \u001B[43m    \u001B[49m\u001B[43mobj\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m   9185\u001B[0m \u001B[43m    \u001B[49m\u001B[43mkeys\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mby\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   9186\u001B[0m \u001B[43m    \u001B[49m\u001B[43maxis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maxis\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   9187\u001B[0m \u001B[43m    \u001B[49m\u001B[43mlevel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlevel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   9188\u001B[0m \u001B[43m    \u001B[49m\u001B[43mas_index\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mas_index\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   9189\u001B[0m \u001B[43m    \u001B[49m\u001B[43msort\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msort\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   9190\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgroup_keys\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup_keys\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   9191\u001B[0m \u001B[43m    \u001B[49m\u001B[43mobserved\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mobserved\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   9192\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdropna\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdropna\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   9193\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/Programming/PyCharm Projects/.venv/lib/python3.12/site-packages/pandas/core/groupby/groupby.py:1329\u001B[0m, in \u001B[0;36mGroupBy.__init__\u001B[0;34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, observed, dropna)\u001B[0m\n\u001B[1;32m   1326\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdropna \u001B[38;5;241m=\u001B[39m dropna\n\u001B[1;32m   1328\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m grouper \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m-> 1329\u001B[0m     grouper, exclusions, obj \u001B[38;5;241m=\u001B[39m \u001B[43mget_grouper\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1330\u001B[0m \u001B[43m        \u001B[49m\u001B[43mobj\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1331\u001B[0m \u001B[43m        \u001B[49m\u001B[43mkeys\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1332\u001B[0m \u001B[43m        \u001B[49m\u001B[43maxis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maxis\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1333\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlevel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlevel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1334\u001B[0m \u001B[43m        \u001B[49m\u001B[43msort\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msort\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1335\u001B[0m \u001B[43m        \u001B[49m\u001B[43mobserved\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mobserved\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mis\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mlib\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mno_default\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mobserved\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1336\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdropna\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdropna\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1337\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1339\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m observed \u001B[38;5;129;01mis\u001B[39;00m lib\u001B[38;5;241m.\u001B[39mno_default:\n\u001B[1;32m   1340\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28many\u001B[39m(ping\u001B[38;5;241m.\u001B[39m_passed_categorical \u001B[38;5;28;01mfor\u001B[39;00m ping \u001B[38;5;129;01min\u001B[39;00m grouper\u001B[38;5;241m.\u001B[39mgroupings):\n",
      "File \u001B[0;32m~/Documents/Programming/PyCharm Projects/.venv/lib/python3.12/site-packages/pandas/core/groupby/grouper.py:1043\u001B[0m, in \u001B[0;36mget_grouper\u001B[0;34m(obj, key, axis, level, sort, observed, validate, dropna)\u001B[0m\n\u001B[1;32m   1041\u001B[0m         in_axis, level, gpr \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m, gpr, \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1042\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1043\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(gpr)\n\u001B[1;32m   1044\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(gpr, Grouper) \u001B[38;5;129;01mand\u001B[39;00m gpr\u001B[38;5;241m.\u001B[39mkey \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m   1045\u001B[0m     \u001B[38;5;66;03m# Add key to exclusions\u001B[39;00m\n\u001B[1;32m   1046\u001B[0m     exclusions\u001B[38;5;241m.\u001B[39madd(gpr\u001B[38;5;241m.\u001B[39mkey)\n",
      "\u001B[0;31mKeyError\u001B[0m: 'Year'"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T11:32:17.509378Z",
     "start_time": "2025-03-08T11:32:17.493083Z"
    }
   },
   "source": [
    "# Create a new Excel writer object\n",
    "with pd.ExcelWriter(f\"{country}_stddev.xlsx\", engine=\"xlsxwriter\") as writer:\n",
    "\n",
    "    for csv_file in csv_files:\n",
    "\n",
    "        # Reading in from CSV File\n",
    "        temp = pd.read_csv(csv_file)\n",
    "\n",
    "        # Convert 'Date' column to datetime\n",
    "        temp['Date'] = pd.to_datetime(temp['Date'])\n",
    "\n",
    "        # Format 'Date' column as Month Month Day Day Year Year (e.g., 'Feb 26 2025')\n",
    "        temp['Date'] = temp['Date'].dt.strftime('%Y-%m-%d')\n",
    "\n",
    "        # Standard Deviation of Stock\n",
    "        df = calculate_yearly_std(temp)\n",
    "\n",
    "        # Merging with Index\n",
    "        df = pd.merge(df, index_std, on='Year', how='inner')\n",
    "\n",
    "        # Calulating Beta & 3 Risks\n",
    "        df = calculate_beta_risks(temp, index, df)\n",
    "\n",
    "        # Ensuring 10 rows are there (2014 to 2023)\n",
    "        df = ensure_minimum_rows(df)\n",
    "        \n",
    "        sheet_name = csv_file[:9] # Remove .csv to use as sheet name\n",
    "        df.to_excel(writer, sheet_name=sheet_name, index=False)  # Write to a separate sheet\n",
    "\n",
    "print(f\"Excel file '{country}_stddev.xlsx' created successfully!\")"
   ],
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'xlsxwriter'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[21], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Create a new Excel writer object\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[43mpd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mExcelWriter\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43mf\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[43mcountry\u001B[49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[38;5;124;43m_stddev.xlsx\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mengine\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mxlsxwriter\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mas\u001B[39;00m writer:\n\u001B[1;32m      4\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m csv_file \u001B[38;5;129;01min\u001B[39;00m csv_files:\n\u001B[1;32m      5\u001B[0m \n\u001B[1;32m      6\u001B[0m         \u001B[38;5;66;03m# Reading in from CSV File\u001B[39;00m\n\u001B[1;32m      7\u001B[0m         temp \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mread_csv(csv_file)\n",
      "File \u001B[0;32m~/Documents/Programming/PyCharm Projects/.venv/lib/python3.12/site-packages/pandas/io/excel/_xlsxwriter.py:197\u001B[0m, in \u001B[0;36mXlsxWriter.__init__\u001B[0;34m(self, path, engine, date_format, datetime_format, mode, storage_options, if_sheet_exists, engine_kwargs, **kwargs)\u001B[0m\n\u001B[1;32m    184\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21m__init__\u001B[39m(\n\u001B[1;32m    185\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m    186\u001B[0m     path: FilePath \u001B[38;5;241m|\u001B[39m WriteExcelBuffer \u001B[38;5;241m|\u001B[39m ExcelWriter,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    195\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    196\u001B[0m     \u001B[38;5;66;03m# Use the xlsxwriter module as the Excel writer.\u001B[39;00m\n\u001B[0;32m--> 197\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mxlsxwriter\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m Workbook\n\u001B[1;32m    199\u001B[0m     engine_kwargs \u001B[38;5;241m=\u001B[39m combine_kwargs(engine_kwargs, kwargs)\n\u001B[1;32m    201\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m mode \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124ma\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'xlsxwriter'"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-08T11:32:17.800934Z",
     "start_time": "2025-03-08T11:32:17.788034Z"
    }
   },
   "source": [
    "with pd.ExcelWriter(f\"{country}_company.xlsx\", engine=\"xlsxwriter\") as writer:\n",
    "    for csv_file in csv_files:\n",
    "        # Read CSV and process stock data\n",
    "        df = pd.read_csv(csv_file)\n",
    "        df = percentage_change(df, index=False)\n",
    "        \n",
    "        # Convert Date columns to datetime (without converting to strings)\n",
    "        df['Date'] = pd.to_datetime(df['Date'])\n",
    "        index_copy = index.copy()\n",
    "        index_copy['Date'] = pd.to_datetime(index_copy['Date'])\n",
    "\n",
    "        # Select relevant columns\n",
    "        df = df[['Date', 'Price', '% Change in Stock Prices']]\n",
    "        index_copy = index_copy[['Date', 'Price', '% Change in Index Level']]\n",
    "        \n",
    "        # Merge using datetime columns\n",
    "        df = pd.merge(df, index_copy, on='Date')\n",
    "        \n",
    "        # Rename columns\n",
    "        df = df.rename(columns={'Price_x': 'Stock Price', 'Price_y': 'Index Level'})\n",
    "\n",
    "        # Write to Excel\n",
    "        sheet_name = csv_file.replace(\".csv\", \"\")[:9]  # Cleaner sheet name\n",
    "        df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "\n",
    "print(f\"Excel file '{country}_company.xlsx' created successfully!\")"
   ],
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'xlsxwriter'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[22], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[43mpd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mExcelWriter\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43mf\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[43mcountry\u001B[49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[38;5;124;43m_company.xlsx\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mengine\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mxlsxwriter\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mas\u001B[39;00m writer:\n\u001B[1;32m      2\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m csv_file \u001B[38;5;129;01min\u001B[39;00m csv_files:\n\u001B[1;32m      3\u001B[0m         \u001B[38;5;66;03m# Read CSV and process stock data\u001B[39;00m\n\u001B[1;32m      4\u001B[0m         df \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mread_csv(csv_file)\n",
      "File \u001B[0;32m~/Documents/Programming/PyCharm Projects/.venv/lib/python3.12/site-packages/pandas/io/excel/_xlsxwriter.py:197\u001B[0m, in \u001B[0;36mXlsxWriter.__init__\u001B[0;34m(self, path, engine, date_format, datetime_format, mode, storage_options, if_sheet_exists, engine_kwargs, **kwargs)\u001B[0m\n\u001B[1;32m    184\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21m__init__\u001B[39m(\n\u001B[1;32m    185\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m    186\u001B[0m     path: FilePath \u001B[38;5;241m|\u001B[39m WriteExcelBuffer \u001B[38;5;241m|\u001B[39m ExcelWriter,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    195\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    196\u001B[0m     \u001B[38;5;66;03m# Use the xlsxwriter module as the Excel writer.\u001B[39;00m\n\u001B[0;32m--> 197\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mxlsxwriter\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m Workbook\n\u001B[1;32m    199\u001B[0m     engine_kwargs \u001B[38;5;241m=\u001B[39m combine_kwargs(engine_kwargs, kwargs)\n\u001B[1;32m    201\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m mode \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124ma\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'xlsxwriter'"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
